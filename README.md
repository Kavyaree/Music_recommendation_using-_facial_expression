# Music_recommendation_using-_facial_expression
# ğŸµ Emotion-Based Music Recommender System

A real-time, emotion-aware music recommender system that captures facial and hand gestures via webcam, classifies your emotion using a deep learning model, and suggests music tailored to your emotional state. Built with **Streamlit**, **MediaPipe**, and a pretrained **Keras model**.

---

## ğŸ“Œ Features

- ğŸ¥ Real-time webcam-based emotion detection
- ğŸ¤– Deep learning model for emotion classification
- ğŸ¯ Facial and hand landmark detection using MediaPipe
- ğŸµ YouTube music recommendations based on detected emotion, language, and singer preferences
- ğŸ’¾ Local session handling with `emotion.npy` and `labels.npy`

---

## ğŸ› ï¸ Tech Stack

| Component         | Technology         |
|------------------|--------------------|
| Web Framework     | Streamlit          |
| Video Processing  | OpenCV + WebRTC    |
| Landmark Detection| MediaPipe          |
| ML Model          | Keras (model.h5)   |
| Emotion Labels    | NumPy              |

---

## ğŸ“‚ File Structure

.
â”œâ”€â”€ music.py # Main Streamlit app
â”œâ”€â”€ model.h5 # Pretrained emotion detection model
â”œâ”€â”€ labels.npy # List of emotion labels
â”œâ”€â”€ emotion.npy # Stores last predicted emotion
â”œâ”€â”€ MUSIC Recommender system.ipynb # Development notebook


---

## ğŸš€ How to Run

1. **Clone the repository**
   ```bash
   git clone https://gitlab.com/your-username/emotion-music-recommender.git
   cd emotion-music-recommender
